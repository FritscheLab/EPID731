[models]
model1 = gpt-4o-2024-05-13

[response_settings]
temperature = 0
max_tokens = 120
top_p = 1.0
frequency_penalty = 0.0
presence_penalty = 0.0

[output_format]
# Specify the format as 'text' or 'csv'
format = txt
include_model = true
include_input_line = true
include_prompt_tokens = true
include_output_tokens = true
